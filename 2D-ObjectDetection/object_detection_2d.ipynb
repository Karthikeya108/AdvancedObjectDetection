{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import WeightReader, decode_netout, draw_boxes\n",
    "from object_detector import ObjectDetector\n",
    "from PIL import Image\n",
    "import vtk\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description & References\n",
    "    + Here we use a pre-trained model (YOLOv2) to detect objects in images. For the concept please refer to the following paper\n",
    "        + https://pjreddie.com/media/files/papers/YOLO9000.pdf\n",
    "    + The implementation is derived from the following keras-yolo2 implementaion \n",
    "        + https://github.com/experiencor/keras-yolo2\n",
    "    + Here is the link to download the YOLOv2 network weights\n",
    "        + https://pjreddie.com/media/files/yolov2.weights\n",
    "    + If the link does not work, download the YOLOv2 weights from the following website\n",
    "        + https://pjreddie.com/darknet/yolo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_path = 'yolov2.weights'\n",
    "objDetector = ObjectDetector(wt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_streampath = '../data/2011_09_26/2011_09_26_drive_0005_sync/image_02/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = objDetector.yoloModelObj.LABELS\n",
    "for fn in os.listdir(img_streampath):\n",
    "    if fn.endswith('png'):\n",
    "        image = Image.open(os.path.join(img_streampath, fn))\n",
    "        annotatedImage, boxes = objDetector.detect_obj(np.array(image.copy()))\n",
    "        cv2.imwrite('./obj-detection-frames/{}'.format(fn), annotatedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.0.1 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with Apple LLVM version 9.1.0 (clang-902.0.39.2)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.0.1 --enable-shared --enable-pthreads --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-gpl --enable-frei0r --enable-libass --enable-libfdk-aac --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopus --enable-librtmp --enable-libspeex --enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libxvid --enable-opencl --enable-videotoolbox --disable-lzma --enable-libopenjpeg --disable-decoder=jpeg2000 --extra-cflags=-I/usr/local/Cellar/openjpeg/2.3.0/include/openjpeg-2.3 --enable-nonfree\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "Input #0, image2, from './obj-detection-frames/*.png':\n",
      "  Duration: 00:00:06.16, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 1242x375, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mprofile High, level 3.1\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'drive-obj-detect.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.12.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1280x720, q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.18.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  154 fps= 38 q=-1.0 Lsize=    6468kB time=00:00:06.04 bitrate=8773.0kbits/s speed=1.49x    \n",
      "video:6466kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.039450%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mframe I:1     Avg QP:27.52  size: 70212\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mframe P:59    Avg QP:27.31  size: 55591\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mframe B:94    Avg QP:28.73  size: 34791\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mconsecutive B-frames: 11.7% 13.0% 23.4% 51.9%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mmb I  I16..4:  4.0% 71.9% 24.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mmb P  I16..4:  3.8% 26.3%  8.2%  P16..4: 29.1% 20.1%  8.4%  0.0%  0.0%    skip: 4.2%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mmb B  I16..4:  1.2%  5.8%  2.6%  B16..8: 43.4% 17.8%  4.4%  direct: 7.9%  skip:17.0%  L0:42.9% L1:36.3% BI:20.8%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0m8x8 transform intra:66.6% inter:70.4%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mcoded y,uvDC,uvAC intra: 76.3% 83.2% 68.2% inter: 44.8% 50.7% 27.7%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mi16 v,h,dc,p: 68% 22%  2%  9%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 14% 16%  6%  8%  9%  8%  8%  9%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 38% 16% 11%  4%  7%  8%  5%  6%  4%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mi8c dc,h,v,p: 50% 17% 28%  5%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mWeighted P-Frames: Y:27.1% UV:15.3%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mref P L0: 50.8% 32.5% 11.5%  4.3%  1.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mref B L0: 94.4%  4.5%  1.1%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mref B L1: 98.9%  1.1%\n",
      "\u001b[1;36m[libx264 @ 0x7fe20700fe00] \u001b[0mkb/s:8597.92\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -pattern_type glob -i './obj-detection-frames/*.png'  -vcodec libx264 -s 1280x720 -pix_fmt yuv420p drive-obj-detect.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"drive-obj-detect.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('drive-obj-detect.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
